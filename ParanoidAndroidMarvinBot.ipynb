{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ParanoidAndroidMarvinBot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNQ01z1id2jk"
      },
      "source": [
        "!pip3 -qqq install pytelegrambotapi --upgrade\n",
        "!pip -qqq install pymorphy2\n",
        "!pip -qqq install python-Levenshtein"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJHQvxC3xS9f"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/tesemnikov-av/ParanoidAndroidMarvinBot/master/CORPUS/top250.csv"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nzoKPE_vnco"
      },
      "source": [
        "from datetime import datetime\n",
        "import Levenshtein\n",
        "import pandas as pd\n",
        "import nltk \n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.stem import wordnet # to perform lemmitization\n",
        "from sklearn.feature_extraction.text import CountVectorizer # to perform bow\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # to perform tfidf\n",
        "from nltk import pos_tag # for parts of speech\n",
        "from sklearn.metrics import pairwise_distances # to perfrom cosine similarity\n",
        "from nltk import word_tokenize # to create tokens\n",
        "from nltk.corpus import stopwords # for stop words\n",
        "import telebot\n",
        "import random\n",
        "import time\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "import pymorphy2\n",
        "import string\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "tfidf = TfidfVectorizer()"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlYkMvoN7N2j"
      },
      "source": [
        "questions = ['Какой фильм тебе нравится?' , 'Дай мне название какого-нибудь фильма.']\n",
        "answers = ['Ты продолжай, когда я тебя пойму, я тебе отвечу...' , 'Давай, накидывай, я разберусь...' , 'Тебя родные хоть понимают?']"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9xVGpCzeKTg"
      },
      "source": [
        "my_stop_words = stopwords.words('russian')\n",
        "my_stop_words.extend(['что', 'это', 'так', 'вот', 'быть', 'как', 'в', '—', '–', 'к', 'на', '...'])"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmqlCt_qZLYM"
      },
      "source": [
        "def tokenize_ru(file_text):\n",
        "  tokens = word_tokenize(file_text)\n",
        "  tokens = [i for i in tokens if (i not in string.punctuation)]\n",
        "  tokens = [i for i in tokens if (i not in my_stop_words)]\n",
        "  tokens = [i.replace(\"«\", \"\").replace(\"»\", \"\") for i in tokens]\n",
        "  tokens = [ morph.parse(i)[0].normal_form for i in tokens ]\n",
        "  return str(tokens).strip('[]').replace(\"'\",\"\").replace(\",\",\"\")"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOp9FABIZv8_"
      },
      "source": [
        "df_top250 = pd.read_csv('top250.csv', sep='#' , names=['original_title','year', 'country' , 'score' , 'overview','director','screenplay' , 'actors' , 'url'])\n",
        "df_top250['overview_tokenize'] = df_top250['overview'].map(lambda x: tokenize_ru(str(x)))\n",
        "df_top250['original_title_lower'] = df_top250['original_title'].map(lambda x: x.lower().strip())\n",
        "df_top250['creators'] = df_top250[df_top250.columns[5:8]].apply(\n",
        "    lambda x: ','.join( x.dropna().astype(str)),\n",
        "    axis=1).apply(lambda x: str(x).replace(\" \",\"\").replace(\",\",\" \"))"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "keqacs7-sCRl",
        "outputId": "0a0d83c8-dd7c-4f5d-a6e9-a89dc9ca979a"
      },
      "source": [
        "df_top250.head(5)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_title</th>\n",
              "      <th>year</th>\n",
              "      <th>country</th>\n",
              "      <th>score</th>\n",
              "      <th>overview</th>\n",
              "      <th>director</th>\n",
              "      <th>screenplay</th>\n",
              "      <th>actors</th>\n",
              "      <th>url</th>\n",
              "      <th>overview_tokenize</th>\n",
              "      <th>original_title_lower</th>\n",
              "      <th>creators</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Побег из Шоушенка</td>\n",
              "      <td>1994</td>\n",
              "      <td>США</td>\n",
              "      <td>9.111</td>\n",
              "      <td>Бухгалтер Энди Дюфрейн обвинён в убийстве собс...</td>\n",
              "      <td>Фрэнк Дарабонт</td>\n",
              "      <td>Фрэнк Дарабонт,  Стивен Кинг</td>\n",
              "      <td>Тим Роббинс, Морган Фриман, Боб Гантон, Уильям...</td>\n",
              "      <td>'https://st.kp.yandex.net/images/film_iphone/i...</td>\n",
              "      <td>бухгалтер энди дюфрейн обвинить убийство собст...</td>\n",
              "      <td>побег из шоушенка</td>\n",
              "      <td>ФрэнкДарабонт ФрэнкДарабонт СтивенКинг ТимРобб...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Зеленая миля</td>\n",
              "      <td>1999</td>\n",
              "      <td>США</td>\n",
              "      <td>9.062</td>\n",
              "      <td>Пол Эджкомб — начальник блока смертников в тюр...</td>\n",
              "      <td>Фрэнк Дарабонт</td>\n",
              "      <td>Фрэнк Дарабонт,  Стивен Кинг</td>\n",
              "      <td>Том Хэнкс, Дэвид Морс, Бонни Хант, Майкл Кларк...</td>\n",
              "      <td>'https://st.kp.yandex.net/images/film_iphone/i...</td>\n",
              "      <td>пол эджкомба начальник блок смертник тюрьма  х...</td>\n",
              "      <td>зеленая миля</td>\n",
              "      <td>ФрэнкДарабонт ФрэнкДарабонт СтивенКинг ТомХэнк...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Форрест Гамп</td>\n",
              "      <td>1994</td>\n",
              "      <td>США</td>\n",
              "      <td>8.913</td>\n",
              "      <td>От лица главного героя Форреста Гампа, слабоум...</td>\n",
              "      <td>Роберт Земекис</td>\n",
              "      <td>Эрик Рот,  Уинстон Грум</td>\n",
              "      <td>Том Хэнкс, Робин Райт, Салли Филд, Гэри Синиз,...</td>\n",
              "      <td>'https://st.kp.yandex.net/images/film_iphone/i...</td>\n",
              "      <td>от лицо главное герой форрест гампа слабоумный...</td>\n",
              "      <td>форрест гамп</td>\n",
              "      <td>РобертЗемекис ЭрикРот УинстонГрум ТомХэнкс Роб...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Список Шиндлера</td>\n",
              "      <td>1993</td>\n",
              "      <td>США</td>\n",
              "      <td>8.817</td>\n",
              "      <td>Фильм рассказывает реальную историю загадочног...</td>\n",
              "      <td>Стивен Спилберг</td>\n",
              "      <td>Стивен Зеллиан,  Томас Кенилли</td>\n",
              "      <td>Лиам Нисон, Бен Кингсли, Рэйф Файнс, Кэролайн ...</td>\n",
              "      <td>'https://st.kp.yandex.net/images/film_iphone/i...</td>\n",
              "      <td>фильм рассказывать реальный история загадочный...</td>\n",
              "      <td>список шиндлера</td>\n",
              "      <td>СтивенСпилберг СтивенЗеллиан ТомасКенилли Лиам...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1+1</td>\n",
              "      <td>2011</td>\n",
              "      <td>Франция</td>\n",
              "      <td>8.807</td>\n",
              "      <td>Пострадав в результате несчастного случая, бог...</td>\n",
              "      <td>Оливье Накаш,  Эрик Толедано</td>\n",
              "      <td>Оливье Накаш,  Филипп Поццо ди Борго,  Эрик Т...</td>\n",
              "      <td>Франсуа Клюзе, Омар Си, Анн Ле Ни, Одри Флеро,...</td>\n",
              "      <td>'https://st.kp.yandex.net/images/film_iphone/i...</td>\n",
              "      <td>пострадать результат несчастный случай богатый...</td>\n",
              "      <td>1+1</td>\n",
              "      <td>ОливьеНакаш ЭрикТоледано ОливьеНакаш ФилиппПоц...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       original_title  ...                                           creators\n",
              "0  Побег из Шоушенка   ...  ФрэнкДарабонт ФрэнкДарабонт СтивенКинг ТимРобб...\n",
              "1       Зеленая миля   ...  ФрэнкДарабонт ФрэнкДарабонт СтивенКинг ТомХэнк...\n",
              "2       Форрест Гамп   ...  РобертЗемекис ЭрикРот УинстонГрум ТомХэнкс Роб...\n",
              "3    Список Шиндлера   ...  СтивенСпилберг СтивенЗеллиан ТомасКенилли Лиам...\n",
              "4                1+1   ...  ОливьеНакаш ЭрикТоледано ОливьеНакаш ФилиппПоц...\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvzTdOzD2JYX"
      },
      "source": [
        "tfidf = TfidfVectorizer(stop_words=my_stop_words)\n",
        "\n",
        "tfidf_matrix_creators = tfidf.fit_transform(df_top250['creators'])\n",
        "cosine_sim_creators = linear_kernel(tfidf_matrix_creators, tfidf_matrix_creators)\n",
        "\n",
        "tfidf_matrix_overview = tfidf.fit_transform(df_top250['overview_tokenize'])\n",
        "cosine_sim_overview = linear_kernel(tfidf_matrix_overview, tfidf_matrix_overview)\n",
        "indices = pd.Series(df_top250.index, index=df_top250['original_title_lower']).drop_duplicates()"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN3HHZE1sQ5L",
        "outputId": "48a47c1d-1b61-4c16-ee8e-14f9b5ed9737"
      },
      "source": [
        "indices"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "original_title_lower\n",
              "побег из шоушенка                          0\n",
              "зеленая миля                               1\n",
              "форрест гамп                               2\n",
              "список шиндлера                            3\n",
              "1+1                                        4\n",
              "                                        ... \n",
              "крамер против крамера                    245\n",
              "пираты карибского моря: на краю света    246\n",
              "иди и смотри                             247\n",
              "профессионал                             248\n",
              "холодное лето пятьдесят третьего...      249\n",
              "Length: 250, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL-dJAfeLsfc"
      },
      "source": [
        "def get_recommendations(title, cosine_sim=cosine_sim_creators ):\n",
        "    idx = indices[title]\n",
        "\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:11]\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    a = df_top250['url'].iloc[movie_indices]\n",
        "    return str(a.values[random.randint(0,9)].capitalize())[1:-1] # a.values , sim_scores"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "P4g8sZDRQS72",
        "outputId": "ee198488-70f8-4bd2-bb5d-7a003cd0d427"
      },
      "source": [
        "get_recommendations('криминальное чтиво')"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://st.kp.yandex.net/images/film_iphone/iphone360_2656.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0PuXgGws1D2"
      },
      "source": [
        "df_dialogs = pd.read_excel('dialog_talk_agent.en.ru (4).xlsx', names=['Context','Text Response'])\n",
        "df_dialogs.ffill(axis = 0,inplace=True)\n",
        "df_dialogs = df_dialogs.append({'Context' : 'Ты повторяешься' , 'Text Response' : 'Да и ты тоже'} , ignore_index=True)\n",
        "df_dialogs = df_dialogs.append({'Context' : 'Пойдем пить пиво' , 'Text Response' : 'Да возьми мне пару баночек'} , ignore_index=True)\n",
        "df_dialogs['lemmatized_text'] = df_dialogs['Context'].map(lambda x: tokenize_ru(str(x)))"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3fI2pUl1-RU"
      },
      "source": [
        "x_tfidf=tfidf.fit_transform((df_dialogs['lemmatized_text'])).toarray() \n",
        "df_tfidf=pd.DataFrame(x_tfidf,columns=tfidf.get_feature_names())"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrrVHnAu2Iia"
      },
      "source": [
        "def chat_tfidf(text):\n",
        "    lemma=tokenize_ru(text) # calling the function to perform text normalization\n",
        "    tf=tfidf.transform([lemma]).toarray() # applying tf-idf\n",
        "    cos=1-pairwise_distances(df_tfidf,tf,metric='cosine') # applying cosine similarity\n",
        "    index_value=cos.argmax() # getting index value \n",
        "    return df_dialogs['Text Response'].loc[index_value]"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4_tvTJLNxEI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd806738-db11-4ebe-e8bd-d94d52745e37"
      },
      "source": [
        "chat_tfidf('Привет! Как дела?')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Тогда ладно.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj5eETxcd9jn"
      },
      "source": [
        "LEV_DIST = 4\n",
        "\n",
        "bot = telebot.TeleBot('1171053774:AAEKARUcqloBdKpZyT9_g4jnIKDcOUJYOKU')\n",
        "# @ParanoidAndroidMarvinBot\n",
        "\n",
        "def random_movie():\n",
        "  return df_top250['original_title'][random.randint(0,len(df_top250['original_title'])-1)]\n",
        "  \n",
        "def get_button():\n",
        "  keyboard1 = telebot.types.ReplyKeyboardMarkup(True, True)\n",
        "  return keyboard1.row(random_movie().capitalize(),random_movie().capitalize(),random_movie().capitalize())\n",
        "  del keyboard1\n",
        "\n",
        "def get_elem(elem):\n",
        "  return elem[random.randint(0, len(elem)-1)]\n",
        "\n",
        "def greating():\n",
        "  hour = int(datetime.strftime(datetime.now()  , '%H')) + 3\n",
        "\n",
        "  if(hour >= 4 and hour < 12):\n",
        "     greeting = \"Доброе утро!\"\n",
        "  elif (hour >= 12 and hour < 16):\n",
        "     greeting = \"Добрый день!\"\n",
        "  elif (hour >= 16 and hour < 23):\n",
        "     greeting = \"Добрый вечер!\"\n",
        "  return greeting\n",
        "\n",
        "@bot.message_handler(commands=['start'])\n",
        "def start_message(message):\n",
        "  bot.send_message(message.chat.id, greating() )\n",
        "  bot.send_sticker(message.chat.id, get_elem(stickers_ids) )\n",
        "  bot.send_message(message.chat.id, get_elem(questions) , parse_mode=\"markdown\" , reply_markup=get_button() ) \n",
        "\n",
        "@bot.message_handler(content_types=['text'])\n",
        "def send_text(message):\n",
        "    recomended = False\n",
        "\n",
        "    for film in list(df_top250['original_title_lower']):\n",
        "      ldis = Levenshtein.distance(message.text.lower(), film)\n",
        "      if ldis < LEV_DIST:\n",
        "        recomended = True\n",
        "        bot.send_photo(message.chat.id, get_recommendations(str(film))) #str(get_recommendations('The Hateful Eight')     )) #    str(get_recommendations('The Hateful Eight')) )\n",
        "       \n",
        "    if recomended != True:\n",
        "   \n",
        "        #time.sleep(1)\n",
        "        bot.send_message(message.chat.id, chat_tfidf(message.text.lower()) , reply_markup=get_button())\n",
        "\n",
        "        if bool(random.choices([True, False], weights=[40, 60])[0]):\n",
        "          bot.send_sticker(message.chat.id, get_elem(stickers_ids) )\n",
        "\n",
        "# get stiker id\n",
        "# @bot.message_handler(content_types=['sticker'])\n",
        "# def sticker_id(message):\n",
        "#     print(message.sticker.file_id)\n",
        "\n",
        "\n",
        "bot.polling()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}